<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="公开课笔记," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="理论知识因子分析（Factor Analysis）因子分析模型（Factor Analysis Model）在因子分析模型中，我们制定了一个在 $(x, z)$ 上的联合分布，如下所示，其中 $z \in R^k$ 是一个潜在随机变量（隐变量）：  上面的式子中，我们这个模型中的参数是向量 $μ \in R^n$ ，矩阵 $Λ \in R^{n×k}$，以及一个对角矩阵 $Ψ \in R^{n×n">
<meta name="keywords" content="公开课笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="第十四集 主成分分析法">
<meta property="og:url" content="http://zzysay.github.io/2017/08/30/cs229-14/index.html">
<meta property="og:site_name" content="ZZY SAY">
<meta property="og:description" content="理论知识因子分析（Factor Analysis）因子分析模型（Factor Analysis Model）在因子分析模型中，我们制定了一个在 $(x, z)$ 上的联合分布，如下所示，其中 $z \in R^k$ 是一个潜在随机变量（隐变量）：  上面的式子中，我们这个模型中的参数是向量 $μ \in R^n$ ，矩阵 $Λ \in R^{n×k}$，以及一个对角矩阵 $Ψ \in R^{n×n">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img008.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img009.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img010.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img011.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img012.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img013.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img014.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img015.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img016.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img007.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img017.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img018.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img019.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img020.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img021.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img022.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img023.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img024.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img025.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img026.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img027.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img028.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img029.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img001.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img002.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img003.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img004.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img005.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img006.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img007.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img008.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note10-img010.jpg">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/css229-note-1401.png">
<meta property="og:updated_time" content="2017-09-11T07:15:52.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第十四集 主成分分析法">
<meta name="twitter:description" content="理论知识因子分析（Factor Analysis）因子分析模型（Factor Analysis Model）在因子分析模型中，我们制定了一个在 $(x, z)$ 上的联合分布，如下所示，其中 $z \in R^k$ 是一个潜在随机变量（隐变量）：  上面的式子中，我们这个模型中的参数是向量 $μ \in R^n$ ，矩阵 $Λ \in R^{n×k}$，以及一个对角矩阵 $Ψ \in R^{n×n">
<meta name="twitter:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note9-img008.jpg?imageMogr2/thumbnail/!75p">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zzysay.github.io/2017/08/30/cs229-14/"/>





  <title>第十四集 主成分分析法 | ZZY SAY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZZY SAY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">I AM WHO I AM.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://zzysay.github.io/2017/08/30/cs229-14/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZHANG ZH.Y.">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZZY SAY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第十四集 主成分分析法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-30T15:11:39+08:00">
                2017-08-30
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/Andrew-Ng公开课/" itemprop="url" rel="index">
                    <span itemprop="name">Andrew Ng公开课</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><h3 id="因子分析（Factor-Analysis）"><a href="#因子分析（Factor-Analysis）" class="headerlink" title="因子分析（Factor Analysis）"></a>因子分析（Factor Analysis）</h3><h4 id="因子分析模型（Factor-Analysis-Model）"><a href="#因子分析模型（Factor-Analysis-Model）" class="headerlink" title="因子分析模型（Factor Analysis Model）"></a>因子分析模型（Factor Analysis Model）</h4><p>在因子分析模型中，我们制定了一个在 $(x, z)$ 上的联合分布，如下所示，其中 $z \in R^k$ 是一个潜在随机变量（隐变量）：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img008.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面的式子中，我们这个模型中的参数是向量 $μ \in R^n$ ，矩阵 $Λ \in R^{n×k}$，以及一个对角矩阵 $Ψ \in R^{n×n}$。$k$ 的值通常都选择比 $n$ 小一点的。这样，我们就设想每个数据点 $x^{(i)}$ 都是通过在一个 $k$ 维度的多元高斯分布 $z^{(i)}$ 中取样获得的。然后，通过计算 $μ+Λz^{(i)}$，就可以映射到实数域 $R^n$ 中的一个 $k$ 维仿射空间，在 $μ + Λz^{(i)}$ 上加上协方差 $Ψ$ 作为噪音，就得到了 $x^{(i)}$。</p>
<a id="more"></a>
<p>反过来，我们也就可以来定义因子分析模型：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img009.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>其中的 $ε$ 和 $z$ 是互相独立的，让我们来确切地看一下这个模型定义的分布。其中，随机变量 $z$ 和 $x$ 有一个联合高斯分布：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img010.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>然后我们要找到 $μ_{zx}$ 和 $Σ$.<br>我们知道 $z$ 的期望 $E[z] = 0$，这是因为 $z$ 服从的是均值为 $0$ 的正态分布 $z ∼ N(0,I)$。 此外我们还知道：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img011.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>综合以上这些条件就得到了：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img012.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>下一步就是要找出 $Σ$，我们需要计算出 $Σ_{zz} = E[(z − E[z])(z − E[z])^T ]$（矩阵 $Σ$ 的左上部分），$Σ_{zx} = E[(z − E[z])(x − E[x])^T]$（右上部分），以及$Σ_{xx} = E[(x − E[x])(x − E[x])^T ]$ （右下部分）。</p>
<p>由于 $z$ 是一个正态分布 $z ∼ N (0, I)$，很容易就能知道 $Σ_{zz} = Cov(z) = I$。另外：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img013.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>在上面的最后一步中，使用到了结论 $E[zz^T] = Cov(z)$（$z$ 的均值为 $0$， $E[zε^T] = E[z]E[ε^T] = 0$， $z$ 和 $ε$ 相互独立，乘积的期望等于期望的乘积）。</p>
<p>同样的方法，我们可以用下面的方法来找到 $Σ_{xx}$：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img014.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>把上面这些综合到一起，就得到了：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img015.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>因此，$x$ 的边界分布为 $x ∼ N(μ,ΛΛ^T +Ψ)$。所以，给定一个训练样本集合 ${x^{(i)}; i = 1, …, m}$，参数的最大似然估计函数的对数函数，就可以写为：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img016.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>为了进行最大似然估计，我们就要最大化上面这个关于参数的函数。但确切地对上面这个方程式进行最大化是很难的，而且没有算法能够以封闭形式来实现这个最大化，所以我们可以使用期望最大化算法。</p>
<h4 id="针对因子分析模型的期望最大化算法（EM-for-Factor-Analysis）"><a href="#针对因子分析模型的期望最大化算法（EM-for-Factor-Analysis）" class="headerlink" title="针对因子分析模型的期望最大化算法（EM for Factor Analysis）"></a>针对因子分析模型的期望最大化算法（EM for Factor Analysis）</h4><p>$E$ 步骤的推导很简单，只需要计算出来 $Q_i(z^{(i)}) = p(z^{(i)}|x^{(i)}; μ, Λ, Ψ)$。把等式 (3) 当中给出的分布代入到方程<img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img007.jpg?imageMogr2/thumbnail/!75p" alt="">来找出一个高斯分布的条件分布，我们就能发现 $z^{(i)}|x^{(i)}; μ, Λ, Ψ ∼ N (μ_{z^{(i)}|x^{(i)} }, Σ_{z^{(i)}|x^{(i)}})$，其中：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img017.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>所以，通过对 $μ_{z^{(i)}|x^{(i)} }$ 和 $Σ_{z^{(i)}|x^{(i)}}$,进行这样的定义就能得到：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img018.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>接下来就是 $M$ 步骤了。需要最大化下面这个关于参数 $μ, Λ, Ψ$ 的函数值：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img019.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>下面对 $Λ$ 进行优化：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img020.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面的等式中，$z^{(i)} ∼ Q_i$ 这个下标，表示的意思是这个期望是关于从 $Q_i$ 中取得的 $z^{(i)}$ 的。在后续的推导过程中，如果没有歧义的情况下，我们就会把这个下标省略掉。删除掉这些不依赖参数的项目后，我们就发现只需要最大化：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img021.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>我们先对上面的函数进行关于 $Λ$ 的最大化。可见只有最后的一项依赖 $Λ$。求导数，同时利用下面几个结论：$tr a = a (a \in R)$, $tr AB = tr BA$, $∇_Atr ABA^T C = CAB + C^TAB$，就能得到：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img022.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>设置导数为 0，然后简化，就能得到：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img023.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>接下来，求解 $Λ$，就能得到：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img024.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>有一个很有意思的地方需要注意，上面这个等式和用最小二乘线性回归推出的正则方程有密切关系：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img025.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>与之类似，这里的 $x$ 是一个关于 $z$ 的线性方程。考虑在 $E$ 步骤中对 $z$ 已经给出了猜测，接下来就可以尝试来对与 $x$ 和 $z$ 相关的未知线性量 $Λ$ 进行估计。接下来我们就会得到某种类似正则方程的结果。然而，这个还是和利用对 $z$ 的“最佳猜测” 进行最小二乘算法有一个很大的区别的。<br>为了完成 $M$ 步骤的更新，接下来我们要解出等式 (7) 当中的期望值。由于我们定义 $Q_i$ 是均值为 $μ_{z^{(i)}|x^{(i)} }$，协方差为 $Σ_{z^{(i)}|x^{(i)}}$ 的一个高斯分布，所以很容易能得到：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img026.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面第二个等式的推导依赖于下面这个事实：对于一个随机变量 $Y$，协方差 $Cov(Y) = E[YY^T]−E[Y]E[Y]^T$ ，所以 $E[YY^T] = E[Y]E[Y]^T +Cov(Y)$。把这个代入到等式 (7)，就得到了 $M$ 步骤中 $Λ$ 的更新规则：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img027.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面这个等式中，要特别注意等号右边这一侧的 $Σ_{z^{(i)}|x^{(i)}}$。这是一个根据 $z^{(i)}$ 给出的 $x^{(i)}$ 后验分布 $p(z^{(i)}|x^{(i)})$ 的协方差，而在 $M$ 步骤中必须要考虑到在这个后验分布中 $z^{(i)}$ 的不确定性。推导 $EM$ 算法的一个常见错误就是在 $E$ 步骤进行假设，只算出潜在随机变量 $z$ 的期望 $E[z]$，然后把这个值放到 $M$ 步骤当中 $z$ 出现的每个地方来进行优化。当然，这能解决简单问题，例如高斯混合模型。在因子模型的推导过程中，就同时需要 $E[zz^T]$ 和 $E[z]$；而我们已经知道，$E[zz^T]$ 和 $E[z]E[z]^T$ 随着 $Σ_{z|x}$ 而变化。因此，在 $M$ 步骤就必须要考虑到后验分布$p(z^{(i)}|x^{(i)})$ 中 $z$ 的协方差。</p>
<p>最后，我们还可以发现，在 $M$ 步骤对参数 $μ$ 和 $Ψ$ 的优化。不难发现其中的 $μ$ 为：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img028.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>由于这个值不随着参数的变换而改变，在算法运行过程中，也不需要进一步更新。类似地，对角矩阵 $Ψ$ 也可以通过计算下面这个式子来获得：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note9-img029.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>并且使 $Ψ_{ii} = Φ_{ii}$（也就是说，设 $Ψ$ 为一个仅仅包含矩阵 $Φ$ 中对角线元素的对角矩阵）。</p>
<h3 id="主成分分析法（Principal-Components-Analysis）"><a href="#主成分分析法（Principal-Components-Analysis）" class="headerlink" title="主成分分析法（Principal    Components Analysis）"></a>主成分分析法（Principal    Components Analysis）</h3><p>前面我们讲了因子分析，其中在某个 $k$ 维度子空间对 $x ∈ R^n$ 进行近似建模（$ k ≪ n$）。具体来说，我们设想每个点 $x^{(i)}$ 用如下方法创建：首先在 $k$ 维度仿射空间 $ {Λz + μ; z ∈ R^k}$ 中生成某个 $z^{(i)}$ ，然后增加 $Ψ$-协方差噪音。因子分析是基于一个概率模型，然后参数估计使用了迭代期望最大化算法。</p>
<p>在本章讲义中，我们要学习一种新的方法，主成分分析（Principal Components Analysis, PCA），这个方法也是用来对数据近似所处的子空间进行判别。然而，主成分分析算法会更加直接，只需要进行一种特征向量计算（在 Matlab 里面可以通过 eig 函数轻松实现），并且不需要再去使用期望最大化算法。</p>
<p>假如我们有一个数据集 ${x^{(i)}; i = 1, . . ., m}$，其中包括了 $m$ 种不同汽车的属性，例如最大速度，转弯半径等等。设其中每个 $i$ 都有 $x^{(i)} ∈ R^n$，$(n ≪ m)$。但对于两个不同的属性，例如 $x_i$ 和 $x_j$，对应着以英里每小时（mph）为单位的最高速度和以公里每小时（kph）为单位的最高速度。因此这两个属性应该基本是线性相关的，只在对 mph 和 kph 进行四舍五入时候会有引入一些微小差异。所以，这个数据实际上应该是近似处于一个 $n-1$ 维度的子空间中的。我们如何自动检测和删除掉这一冗余呢？</p>
<p>举一个不那么麻烦的例子，设想有一个数据集，其中包含的是对一个无线电遥控直升机飞行员协会进行调查得到的数据，其中的 $x_1^{(i)}$ 指代的是飞行员 $i$ 的飞行技能的度量，而 $x_2^{(i)}$ 指代的是该飞行员对飞行的喜爱程度。无线电遥控直升机是很难操作的，只有那些非常投入，并且特别热爱飞行的学生，才能成为好的飞行员。所以，上面这两个属性 $x_1$ 和 $x_2$ 之间的相关性是非常强的。所以我们可以认为在数据中沿着对角线方向（也就是下图中的 $u_1$ 方向）表征了一个人对飞行投入程度的内在“源动力”，只有少量的噪音脱离这个对角线方向。如下图所示，我们怎么来自动去计算出 $u_1$ 的方向呢？</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img001.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>我们接下来很快就要讲到主成分分析算法了。但在运行 PCA 之前，我们首先要进行一些预处理，正则化数据的均值和方差，如下所示：</p>
<ol>
<li>设 <img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img002.jpg?imageMogr2/thumbnail/!75p" alt=""></li>
<li>将每个 $x^{(i)}$ 替换成 $x^{(i)}-μ$. </li>
<li>设 <img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img003.jpg?imageMogr2/thumbnail/!75p" alt=""></li>
<li>将每个 $x^{(i)}$ 替换成 $x^{(i)} / σ_j$. </li>
</ol>
<p>第（1-2）步把数据的平均值清零，然后可以省略掉所有有零均值的数据（例如，对应语音或者其他声学信号的时间序列）。第（3-4）步将每个坐标缩放，使之具有单位方差，这确保了不同的属性都在同样的“尺度”上来进行处理。例如，如果 $x_1$ 是汽车的最大速度（以 mph 为单位，精确到十位），然后 $x_2$ 是汽车的座位数量（取值一般在 2-4），这样这个重新正则化就把不同的属性进行了缩放，然后这些不同属性就更具有对比性。如果我们事先已经知道不同的属性在同一尺度上，就可以省略第（3-4）步。例如，如果每个数据点表示灰度图像中的每个数据点，而每个 $x_j^{(i)}$ 就从 ${0, 1, . . . , 255}$ 中取值，对应的也就是在图像 $i$ 中像素 $j$ 位置的灰度值。</p>
<p>接下来，进行了正则化之后，对数据近似所处的方向，也就是“主要变异轴” $u$，该如何去计算呢？一种方法是找出一个单位向量$u$，使得数据投影在 $u$ 的方向上的时候，投影的数据的方差最大。<br>直观来看，在这个方向上，数据开始有一定规模的方差/信息量。我们要选择的是这样一个方向的单位向量 $u$：数据能近似投放到与单位向量 $u$ 一致的方向/子空间，并且尽可能多地保留上面的方差。</p>
<p>设下面的数据集，我们已经进行了正则化步骤：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img004.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>现在，加入我们选择的单位向量 $u$ 对应了下图中所示的方向。下图中的圆点表示的就是原始数据在这条线上面的投影。</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img005.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>可以看到，上面投影得到的数据依然有还算比较大的方差，而这些点距离零点也都比较远。反面样本则如下图所示，我们选择了另外一个方向的单位向量：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img006.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面这幅图的投影中的方差就明显小了很多，而且投影得到的点位置也距离原点更近很多。</p>
<p>我们希望能自动地选择出来如上面两幅图中第一幅那样的方向的单位向量 $u$。要对这个过程进行方程化，要注意到给定一个向量 $u$ 和一个点 $x$，$x$ 投影到 $u$ 上的投影长度就可以用 $x^T u$ 来得到。也就是说，如果 $x^{(i)}$ 是我们数据集中的一个点，那么这个点在 $u$ 上的投影就是从原点到 $x^T u$ 的距离。因此，要最大化投影的方差，就要找到一个能够将下面式子最大化的单位长度向量 $u$：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img007.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>很容易就能发现，要让上面的式子最大化，$||u||_2 = 1$ 给出了<img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img008.jpg?imageMogr2/thumbnail/!75p" alt=""> 的主特征向量，而这也正好就是数据的经验协方差矩阵（假设有零均值）。<br>如果我们要找一个 1 维度子控件来近似数据，就要选择 $Σ$ 的主特征向量作为单位向量 $u$。更广义地理解，就是如果要讲数据投影到一个 $k$ 维度子空间$（k &lt; n）$，就应当选择 $Σ$ 的 $k$ 个特征向量 来作为单位向量 $u_1, . . ., u_k$。这里的 $u_i$ 就形成了数据的一组新的正交基。</p>
<p>然后，要使用这组正交基来表示 x(i)，只需要计算对应的向量：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note10-img010.jpg" alt=""></p>
<p>因此，$x^{(i)} ∈ R^n$，向量 $y^{(i)}$ 就是对 $x^{(i)}$ 的近似表示。因此，主成分分析算法（PCA）也被称为是一种降维算法。而其中的单位向量 $u_1,…,u_k$ 也就叫做数据集的前 $k$ 个主成分。</p>
<p>备注：虽然我们已经正式表述了，仅当 $k = 1$的情况下，使用特征向量 的众所周知的特性，很明显，在所有可能的正交基当中，我们选择的那一组就能使得取最大值。因此，我们对基向量的选择应当是尽可能保留原始数据的方差信息。</p>
<p>主成分分析算法也可以有另外一种推导方式：将数据投影到 $k$ 维度子空间中，选择一组基向量，使得投影引起的近似误差最小。</p>
<p>主成分分析算法有很多用法；首先是压缩—用更低维度的 $y^{(i)}$ 来表示 $x^{(i)}$ ，如果我们把高维度的数据降维到 $k = 2$ 或者 $3$，那么就可以将 $y^{(i)}$ 进行可视化了。例如，如果我们把汽车数据降维到 $2$ 维，那么就可以把压缩后的数据投图（例如这时候投图中的一二点可能就代表了骑车的类型），来看看哪些车彼此相似，以及这些车可以聚集成那些组。<br>另一个常用应用就是在使用 $x^{(i)}$ 作为输入特征进行监督学习算法之前数据降维的预处理步骤。除了有利于缓解计算性能压力之外，数据降维还可以降低假设类的复杂度，然后避免过拟合（例如，低维度的输入特征控件上的线性分类器会有更小的 VC 维度）。<br>最后，正如在遥控直升机飞行员那个样例，我们可以把 PCA 用作为一种降噪算法。。在课程中，我们还看到了把这种思路用于人脸图像，得到的就是面部特征算法。其中每个点 $x^{(i)} ∈ R^{100×100}$ 都是一个 $10000$ 维度的向量，每个坐标对应的是一个 $100x100$ 的人脸图像中的一个像素灰度值。使用主成分分析算法，我们就可以用更低维度的 $y^{(i)}$ 来表示每个图像 $x^{(i)}$。在这个过程中，我们希望主成分能够保存有趣的信息、面孔之间的系统变化，一遍能捕获到一个人看上去的模样，而不是由于细微的光线变化、轻微的拍摄状况差别等而引起的图像中的“噪音”。然后我们通过降低纬度然后计算 $||y^{(i)} − y^{(j)}||^2$ 来测量面孔 $i$ 和 $j$ 之间的距离。这样就能得到一个令人惊艳的面部匹配和检索算法。</p>
<h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line">scaled_x = np.array([<span class="number">2.5</span>, <span class="number">0.5</span>, <span class="number">2.2</span>, <span class="number">1.9</span>, <span class="number">3.1</span>, <span class="number">2.3</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">1.5</span>, <span class="number">1.1</span>])</div><div class="line">scaled_y = np.array([<span class="number">2.4</span>, <span class="number">0.7</span>, <span class="number">2.9</span>, <span class="number">2.2</span>, <span class="number">3</span>, <span class="number">2.7</span>, <span class="number">1.6</span>, <span class="number">1.1</span>, <span class="number">1.6</span>, <span class="number">0.9</span>])</div><div class="line">data = np.matrix([[scaled_x[i], scaled_y[i]] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(scaled_x))])</div><div class="line"></div><div class="line">mean_x = np.mean(scaled_x)</div><div class="line">mean_y = np.mean(scaled_y)</div><div class="line">scaled_x = scaled_x-mean_x</div><div class="line">scaled_y = scaled_y-mean_y</div><div class="line">data = np.matrix([[scaled_x[i], scaled_y[i]] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(scaled_x))])</div><div class="line"></div><div class="line"><span class="comment"># plt.plot(scaled_x, scaled_y, 'o')</span></div><div class="line"><span class="comment"># plt.show()</span></div><div class="line"></div><div class="line">cov = np.cov(scaled_x, scaled_y)</div><div class="line"></div><div class="line">np.dot(np.transpose(data), data)</div><div class="line"></div><div class="line">eig_val, eig_vec = np.linalg.eig(cov)</div><div class="line"></div><div class="line">plt.plot(scaled_x,scaled_y,<span class="string">'o'</span>,)</div><div class="line">xmin, xmax = scaled_x.min(), scaled_x.max()</div><div class="line">ymin, ymax = scaled_y.min(), scaled_y.max()</div><div class="line">dx = (xmax - xmin) * <span class="number">0.2</span></div><div class="line">dy = (ymax - ymin) * <span class="number">0.2</span></div><div class="line"></div><div class="line"><span class="comment"># plt.xlim(xmin - dx, xmax + dx)</span></div><div class="line"><span class="comment"># plt.ylim(ymin - dy, ymax + dy)</span></div><div class="line"><span class="comment"># plt.plot([eig_vec[:, 0][0], 0], [eig_vec[:, 0][1], 0], color='red')</span></div><div class="line"><span class="comment"># plt.plot([eig_vec[:, 1][0], 0], [eig_vec[:, 1][1], 0], color='red')</span></div><div class="line"><span class="comment"># plt.show()</span></div><div class="line"></div><div class="line">new_data = np.transpose(np.dot(eig_vec, np.transpose(data)))</div><div class="line"></div><div class="line">eig_pairs = [(np.abs(eig_val[i]), eig_vec[:, i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(eig_val))]</div><div class="line">eig_pairs.sort(reverse=<span class="keyword">True</span>)</div><div class="line"></div><div class="line">feature = eig_pairs[<span class="number">0</span>][<span class="number">1</span>]</div><div class="line"></div><div class="line">new_data_reduced = np.transpose(np.dot(feature, np.transpose(data)))</div><div class="line"></div><div class="line">plt.plot(scaled_x,scaled_y,<span class="string">'o'</span>,color=<span class="string">'red'</span>)</div><div class="line">plt.plot([eig_vec[:,<span class="number">0</span>][<span class="number">0</span>],<span class="number">0</span>],[eig_vec[:,<span class="number">0</span>][<span class="number">1</span>],<span class="number">0</span>],color=<span class="string">'red'</span>)</div><div class="line">plt.plot([eig_vec[:,<span class="number">1</span>][<span class="number">0</span>],<span class="number">0</span>],[eig_vec[:,<span class="number">1</span>][<span class="number">1</span>],<span class="number">0</span>],color=<span class="string">'blue'</span>)</div><div class="line">plt.plot(new_data[:,<span class="number">0</span>],new_data[:,<span class="number">1</span>],<span class="string">'^'</span>,color=<span class="string">'blue'</span>)</div><div class="line">plt.plot(new_data_reduced[:,<span class="number">0</span>],[<span class="number">1.2</span>]*<span class="number">10</span>,<span class="string">'*'</span>,color=<span class="string">'green'</span>)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p><img src="http://otceoztx6.bkt.clouddn.com/css229-note-1401.png" alt=""></p>
<p>绿色的五角星是PCA处理过后得到的一维数据，为了能跟以前的图对比，将他们的高度定位1.2，其实就是红色圆点投影到蓝色线之后形成的点。这就是PCA,通过选择特征根向量，形成新的坐标系，然后数据投影到这个新的坐标系，在尽可能少的丢失信息的基础上实现降维。</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/公开课笔记/" rel="tag"># 公开课笔记</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/21/cs229-13/" rel="next" title="第十三集 高斯混合模型">
                <i class="fa fa-chevron-left"></i> 第十三集 高斯混合模型
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/09/10/cs229-15/" rel="prev" title="第十五集 独立成分分析法">
                第十五集 独立成分分析法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="ZHANG ZH.Y." />
          <p class="site-author-name" itemprop="name">ZHANG ZH.Y.</p>
           
              <p class="site-description motion-element" itemprop="description">一个<br>为了不做程序员而努力搬砖的<br>代码狗</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#理论知识"><span class="nav-number">1.</span> <span class="nav-text">理论知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#因子分析（Factor-Analysis）"><span class="nav-number">1.1.</span> <span class="nav-text">因子分析（Factor Analysis）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#因子分析模型（Factor-Analysis-Model）"><span class="nav-number">1.1.1.</span> <span class="nav-text">因子分析模型（Factor Analysis Model）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#针对因子分析模型的期望最大化算法（EM-for-Factor-Analysis）"><span class="nav-number">1.1.2.</span> <span class="nav-text">针对因子分析模型的期望最大化算法（EM for Factor Analysis）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主成分分析法（Principal-Components-Analysis）"><span class="nav-number">1.2.</span> <span class="nav-text">主成分分析法（Principal    Components Analysis）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#代码实现"><span class="nav-number">2.</span> <span class="nav-text">代码实现</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZHANG ZH.Y.</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
