<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="公开课笔记," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="理论知识目前为止，我们讲过的学习算法的模型都是 $p(y|x;θ)$，也就是给定 $x$ 下的 $y$ 的条件分布，以 $θ$ 为参数。例如，逻辑回归中就是以 $h_θ(x) = g(θ^T x)$ 作为 $p (y|x;θ)$ 的模型，这里的 $g$ 是一个 S型函数（sigmoid function）。接下来，我们要讲一种不同类型的学习算法。 设想有这样一种分类问题，我们要学习基于一个动物的某">
<meta name="keywords" content="公开课笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="第五集 生成学习算法">
<meta property="og:url" content="http://zzysay.github.io/2017/08/01/cs229-5/index.html">
<meta property="og:site_name" content="ZZY SAY">
<meta property="og:description" content="理论知识目前为止，我们讲过的学习算法的模型都是 $p(y|x;θ)$，也就是给定 $x$ 下的 $y$ 的条件分布，以 $θ$ 为参数。例如，逻辑回归中就是以 $h_θ(x) = g(θ^T x)$ 作为 $p (y|x;θ)$ 的模型，这里的 $g$ 是一个 S型函数（sigmoid function）。接下来，我们要讲一种不同类型的学习算法。 设想有这样一种分类问题，我们要学习基于一个动物的某">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img001.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img002.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img003.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img004.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img005.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img006.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img007.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img008.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img009.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img010.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img011.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img012.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img013.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img014.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img015.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img016.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img017.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img018.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img019.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img020.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img021.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img022.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img023.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img024.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img025.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/css229-note-0501.png">
<meta property="og:updated_time" content="2017-08-31T02:55:48.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第五集 生成学习算法">
<meta name="twitter:description" content="理论知识目前为止，我们讲过的学习算法的模型都是 $p(y|x;θ)$，也就是给定 $x$ 下的 $y$ 的条件分布，以 $θ$ 为参数。例如，逻辑回归中就是以 $h_θ(x) = g(θ^T x)$ 作为 $p (y|x;θ)$ 的模型，这里的 $g$ 是一个 S型函数（sigmoid function）。接下来，我们要讲一种不同类型的学习算法。 设想有这样一种分类问题，我们要学习基于一个动物的某">
<meta name="twitter:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note2-img001.jpg?imageMogr2/thumbnail/!50p">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zzysay.github.io/2017/08/01/cs229-5/"/>





  <title>第五集 生成学习算法 | ZZY SAY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZZY SAY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">I AM WHO I AM.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://zzysay.github.io/2017/08/01/cs229-5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZHANG ZH.Y.">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZZY SAY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第五集 生成学习算法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-01T17:24:34+08:00">
                2017-08-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/Andrew-Ng公开课/" itemprop="url" rel="index">
                    <span itemprop="name">Andrew Ng公开课</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><p>目前为止，我们讲过的学习算法的模型都是 $p(y|x;θ)$，也就是给定 $x$ 下的 $y$ 的条件分布，以 $θ$ 为参数。例如，逻辑回归中就是以 $h_θ(x) = g(θ^T x)$ 作为 $p (y|x;θ)$ 的模型，这里的 $g$ 是一个 S型函数（sigmoid function）。接下来，我们要讲一种不同类型的学习算法。</p>
<p>设想有这样一种分类问题，我们要学习基于一个动物的某个特征来辨别它是大象（$y=1$）还是小狗 ( $y=0$ ) 。给定一个训练集，用逻辑回归或者感知器算法（perceptron algorithm）能找到一条直线，作为区分开大象和小狗的边界。接下来，要辨别一个新的动物是大象还是小狗，程序就要检查这个新动物的值落到了划分出来的哪个区域中，然后根据所落到的区域来给出预测。</p>
<a id="more"></a>
<p>还有另外一种方法。首先，观察大象，然后我们针对大象的样子来进行建模。然后，再观察小狗，针对小狗的样子另外建立一个模型。最后要判断一种新动物归属哪一类，我们可以把新动物分别用大象和小狗的模型来进比对，看看新动物更接近哪个训练集中已有的模型。</p>
<p>例如逻辑回归之类的直接试图建立 $p(y|x)$的算法，以及感知器算法（perceptron algorithm）等直接用投图（mappings directly）的思路来判断对应 $X$ 的值落到了 ${0, 1}$中哪个区域的算法，这些都叫判别式学习算法（discriminative learning algorithms）。和之前的这些判别式算法不同，下面我们要讲的新算法是对 $p(x|y)$和 $p(y)$来进行建模。这类算法叫<strong>做生成学习算法（generative learning algorithms）</strong>。例如如果 $y$ 是用来表示一个样例是小狗 $(0)$ 或者大象 $(1)$，那么$p(x|y=0)$就是对小狗特征的分布的建模，而$p(x|y=1)$就是对大象特征分布的建模。</p>
<p>对 $p(y)$ 和$p(x|y)$ 进行建模之后，我们的算法用<strong>贝叶斯规则（Bayes rule）</strong>来推导对应给定的 $x$ 的 $y$ 的<strong>后验分布（posterior distribution）</strong>：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img001.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>这里的分母为：$p(x) = p(x|y=1)p(y=1) + p(x|y=0)p(y=0)$， 这样接下来就可以把它表示成我们熟悉的 $p(x|y)$ 和 $p(y)$ 的形式了。实际上如果我们计算 $p(y|x)$ 来进行预测，那就并不需要去计算这个分母，因为有下面的等式关系：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img002.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<h3 id="高斯判别分析（Gaussian-Discriminant-Analysis）"><a href="#高斯判别分析（Gaussian-Discriminant-Analysis）" class="headerlink" title="高斯判别分析（Gaussian Discriminant Analysis）"></a>高斯判别分析（Gaussian Discriminant Analysis）</h3><p>在这个模型里面，我们假设 $p(x|y)$ 是一个多元正态分布。所以我们首先讲一下多元正态分布的一些特点，然后再继续讲 $GDA$ 高斯判别分析模型。</p>
<h4 id="多元正态分布（Multivariate-Normal-Distribution）"><a href="#多元正态分布（Multivariate-Normal-Distribution）" class="headerlink" title="多元正态分布（Multivariate Normal Distribution）"></a>多元正态分布（Multivariate Normal Distribution）</h4><p>$n$ 维多元正态分布，也叫做多变量高斯分布，参数为一个均值 $n$ 维向量 $μ ∈ R^n$，以及一个协方差矩阵 $Σ ∈ R^{n×n}$，其中 $Σ≥0$ 是一个对阵的半正定矩阵。当然也可以写成 $N (μ, Σ)$  的分布形式，密度函数为：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img003.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>在上面的等式中，$|Σ|$ 的意思是矩阵 $Σ$ 的行列式。对于一个在 $N(μ,Σ)$ 分布中的随机变量 $X$ ，其均值就是 $μ$：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img004.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>随机变量Z是一个有值的向量，$Z$ 的协方差的定义是：$Cov(Z) = E[(Z-E[Z]) (Z-E[Z])^T]$。这是对实数随机变量的方差这一概念的泛化扩展。这个协方差还可以定义成 $Cov(Z) = E[ZZ^T]-(E[Z])(E[Z])^T$，如果 $X$ 是一个多变量正态分布，即 $X \sim N (μ, Σ)$，则有：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img005.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>下面这些样例是一些高斯分布的密度图，如下图所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img006.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>最左边的图，展示的是一个均值为 $0$（实际上是一个 $2 \times 1$ 的零向量）的高斯分布，协方差矩阵就是 $Σ = I$ (一个 $2\times 2$ 的单位矩阵)。这种均值为 $0$ 并且协方差矩阵为单位矩阵的高斯分布也叫做标准正态分布。中间的图中展示的是均值为 $0$ 而协方差矩阵是 $0.6I$ 的高斯分布的密度；最右边的展示的协方差矩阵为 $2I$。从这几个图可以看出，随着协方差矩阵 $Σ$ 变大，高斯分布的形态就变得更宽平，而如果协方差矩阵 $Σ$ 变小，分布就会更加集中。</p>
<p>来看一下更多的样例：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img007.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面这几个图展示的是均值为 $0$，但协方差矩阵各不相同的高斯分布，其中的协方差矩阵依次如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img008.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>第一幅图还跟之前的标准正态分布的样子很相似，然后我们发现随着增大协方差矩阵 $Σ$ 的反对角线的值，密度图像开始朝着 45° 方向 (也就是 $x_1 = x_2$ 所在的方向)逐渐压缩。  看一下三个同样分布密度图的轮廓图能看得更明显：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img009.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>下面的是另外一组样例，调整了协方差矩阵 $Σ$ :</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img010.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面这三个图像对应的协方差矩阵分别如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img011.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>从最左边的到中间，很明显随着协方差矩阵中右上左下这个对角线方向元素的值的降低，图像还是又被压扁了，只是方向是反方向的。最后，随着我们修改参数，通常生成的轮廓图都是椭圆。</p>
<p>再举一些例子，固定协方差矩阵为单位矩阵，即 $Σ = I$，然后调整均值 $μ$，我们就可以让密度图像随着均值而移动：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img012.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>上面的图像中协方差矩阵都是单位矩阵，即 $Σ = I$，对应的均值 $μ$ 如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img013.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<h4 id="高斯判别分析模型（Gaussian-Discriminant-Analysis-Model）"><a href="#高斯判别分析模型（Gaussian-Discriminant-Analysis-Model）" class="headerlink" title="高斯判别分析模型（Gaussian Discriminant Analysis Model）"></a>高斯判别分析模型（Gaussian Discriminant Analysis Model）</h4><p>假如我们有一个分类问题，其中输入特征 $x$ 是一系列的连续随机变量，那就可以使用高斯判别分析（Gaussian Discriminant Analysis，GDA）模型，其中对 $p(x|y)$ 用多元正态分布来进行建模。这个模型为：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img014.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>分布写出来的具体形式如下：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img015.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>在上面的等式中，模型的参数包括 $φ, Σ, μ_0$ 和 $μ_1$。取对数似然函数如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img016.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>通过使 $l$ 取得最大值，找到对应的参数组合，然后就能找到该参数组合对应的最大似然估计，如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img017.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>用图形化的方式来表述，这个算法可以按照下面的图示所表示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img018.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>图中展示的点就是训练数据集，图中的两个高斯分布就是针对两类数据各自进行的拟合。要注意这两个高斯分布的轮廓图有同样的形状和拉伸方向，这是因为他们都有<strong>同样的协方差矩阵 $Σ$</strong>，但他们有<strong>不同的均值 $μ_0$ 和 $μ_1$</strong> 。此外，图中的直线给出了 $p(y=1|x) = 0.5$ 这条边界线。在这条边界的一侧，我们预测 $y=1$ 是最大可能的结果，而另一侧，就估计 $y=0$。</p>
<h4 id="高斯判别分析与逻辑回归（GDA-and-Logistic-Regression）"><a href="#高斯判别分析与逻辑回归（GDA-and-Logistic-Regression）" class="headerlink" title="高斯判别分析与逻辑回归（GDA and Logistic Regression）"></a>高斯判别分析与逻辑回归（GDA and Logistic Regression）</h4><p>高斯判别分析模型与逻辑回归有很有趣的相关性。如果我们把变量 $p(y = 1|x; φ, μ0, μ1, Σ)$ 作为一个 $x$ 的函数，就会发现可以用如下的形式来表达：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img019.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>其中的 $θ$ 是对 $φ, Σ, μ_0, μ_1$的某种函数。这就是逻辑回归用来对 $p(y=1|x)$ 建模的形式。</p>
<p>这两个模型中什么时候该选哪一个呢？一般来说，高斯判别分析和逻辑回归，对同一个训练集，可能给出的判别曲线是不一样的。哪一个更好些呢？</p>
<p>我们刚刚已经表明，如果$p(x|y)$是一个多变量的高斯分布（且具有一个共享的协方差矩阵 $Σ$），那么$p(y|x)$则必然符合一个逻辑函数（logistic function）。然而，反过来，这个命题是不成立的。例如假如 $p(y|x)$ 是一个逻辑函数，这并不能保证 $p(x|y)$ 一定是一个多变量的高斯分布。这就表明高斯判别模型能比逻辑回归对数据进行更强的建模和假设,这也就意味着，在这两种模型假设都可用的时候，高斯判别分析法去拟合数据是更好的。尤其当$p(x|y)$已经确定是一个高斯分布（有共享的协方差矩阵$Σ$），那么高斯判别分析是渐进有效的。实际上，这也意味着，在面对非常大的训练集的时候，高斯判别分析是一个比逻辑回归更好的算法；再扩展一下，即便对于小规模的训练集，我们最终也会发现高斯判别分析是更好的。</p>
<p>然而由于逻辑回归做出的假设要明显更弱一些，所以因此逻辑回归给出的判断也更健壮，也对错误的建模假设不那么敏感。有很多不同的假设集合都能够将 $p(y|x)$ 引向逻辑回归函数。例如，如果 $x|y = 0 \sim Poisson(λ_0)$ 是一个泊松分布，而 $x|y = 1 \sim Poisson(λ_1)$ 也是一个泊松分布，那么 $p(y|x)$ 也将是适合逻辑回归的。逻辑回归也正适用于这类的泊松分布的数据。但对这样的数据，如果我们强行用高斯分布来拟合这些非高斯数据，那么结果的可预测性就会降低。</p>
<p>总结：高斯判别分析方法能够建立更强的模型假设，并且在数据利用上更加有效，其前提是模型假设正确或者至少接近正确。逻辑回归建立的假设更弱，因此对于偏离的模型假设来说更加健壮得多。然而，如果训练集数据的确是非高斯分布的，而且是有限的大规模数据，那么逻辑回归几乎总是比高斯判别分析方法要好。因此，在实际中，逻辑回归的使用频率要比 GDA 高得多。</p>
<h3 id="朴素贝叶斯算法（Naive-Bayes）"><a href="#朴素贝叶斯算法（Naive-Bayes）" class="headerlink" title="朴素贝叶斯算法（Naive Bayes）"></a>朴素贝叶斯算法（Naive Bayes）</h3><p>在高斯判别分析方法中，特征向量 $x$ 是连续的，值为实数的向量。下面我们要讲的是当 $x_i$ 是离散值的时候来使用的另外一种学习算法。</p>
<p>下面就来继续看一个之前见过的样例，来尝试建立一个邮件筛选器，使用机器学习的方法。我们要来对邮件信息进行分类，来判断是否为商业广告邮件，还是非垃圾邮件。在学会了怎么实现之后，我们就可以让邮件阅读器能够自动对垃圾信息进行过滤，或者单独把这些垃圾邮件放进一个单独的文件夹中。对邮件进行分类是一个案例，属于文本分类这一更广泛问题集合。</p>
<p>假设我们有了一个训练集（一堆已经标好了是否为垃圾邮件的邮件）。要构建垃圾邮件分选器，咱们先要开始确定用来描述一封邮件的特征 $x_i$ 有哪些。</p>
<p>我们将用一个特征向量来表示一封邮件，这个向量的长度等于字典中单词的个数。如果邮件中包含了字典中的第 $i$ 个单词，那么久令 $x_i = 1$；反之则 $x_i = 0$。例如下面这个向量：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img020.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>就用来表示一个邮件，其中包含了两个单词 “a” 和 “buy”，但没有单词 “aardvark”， “aardwolf” 或者 “zymurgy”  。这个单词集合编码整理成的特征向量也成为词汇表，所以特征向量 $x$ 的维度就等于词汇表的长度。</p>
<p>注：实际应用中并不需要遍历整个英语词典来组成所有英语单词的列表，实践中更常用的方法是遍历一下训练集，然后把出现过一次以上的单词才编码成特征向量。这样做除了能够降低模型中单词表的长度之外，还能够降低运算量和空间占用，此外还有一个好处就是能够包含一些你的邮件中出现了而词典中没有的单词，比如本课程的缩写CS229。还要排除一些特别高频率的词汇，比如像冠词 the，介词 of 和 and 等等；这些高频率但是没有具体意义的虚词也叫做 stop words。</p>
<p>选好了特征向量了，接下来就是建立一个生成模型（generative model）。所以我们必须对 $p(x|y)$ 进行建模。但是，假如我们的单词有五万个词，则特征向量 $ x ∈ {0, 1}^{50000} $ (即 x 是一个 50000维的向量，其值是0或者1)，如果我们要对这样的 x 进行多项式分布的建模，那么就可能有 250000 种可能的输出，然后就要用一个 $ 2^{50000}-1 $  维的参数向量。这样参数明显太多了。</p>
<p>要给 $p(x|y)$ 建模，先来做一个非常强的假设。我们假设特征向量 $x_i$ 对于给定的 $y$ 是独立的。这个假设也叫做朴素贝叶斯假设，基于此假设衍生的算法也就叫做朴素贝叶斯分选器。例如，如果 $y = 1$ 意味着一个邮件是垃圾邮件；然后其中 “buy” 是第2087个单词，而 “price” 是第39831个单词；那么接下来我们就假设，如果我告诉你 $y = 1$，也就是说某一个特定的邮件是垃圾邮件，那么对于 $ x_{2087} $ （单词 buy 是否出现在邮件里）的了解并不会影响你对 $ x_{39831} $ （单词 price 出现）的可信值。（这并不是说这两个特征是独立的，那样就变成了 $ p(x_{2087}) = p(x_{2087}|x_{39831}) $，我们只是说在给定了 $y$ 的条件下，二者才是有条件的独立。）</p>
<p>然后我们就得到了等式：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img021.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>第一行的等式就是简单地来自概率的基本性质，第二个等式则使用了朴素贝叶斯假设。这里要注意，朴素贝叶斯假设也是一个很强的假设，产生的这个算法可以适用于很多种问题。</p>
<p>我们这个模型的参数为 $φ_{i|y=1} = p(x_i=1|y=1)$, $φ_{i|y=0} = p(x_i=1|y=0)$, 而 $φ_y = p(y=1)$ 。和以往一样，给定一个训练集 ${(x^{(i)},y^{(i)}); i = 1, …, m}$，就可以写出下面的联合似然函数：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img022.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>找到使联合似然函数取得最大值的对应参数组合 $φ_y$ , $φ_{i|y=0}$ 和 $φ_{i|y=1}$ 就给出了最大似然估计：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img023.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>在上面的等式中，这些参数有一个非常自然的解释。例如第一个等式等号左边的 $φ_{j|y=1}$ 正是单词 $j$ 出现的邮件中垃圾邮件 $y=1$ 所占的比例。</p>
<p>拟合好了全部这些参数之后，要对一个新样本的特征向量 $x$ 进行预测，只要进行如下的简单地计算：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img024.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>然后选择最高后验概率的概率。</p>
<p>最后我们要注意，刚刚我们对朴素贝叶斯算法的使用中，特征向量 $x_i$ 都是二值化的，其实特征向量也可以是多个离散值，比如 ${1, 2, …, k_i}$ 。这时候只需要把对 $p(x_i|y)$  的建模从伯努利分布改成多项式分布。实际上，即便一些原始的输入值是连续值也可以转换成一个小规模的离散值的集合，然后再使用朴素贝叶斯方法。例如，如果我们用特征向量 xi 来表示第一个案例中的住房面积，那么就可以按照下面所示的方法来对这一变量进行离散化：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note2-img025.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>这样，对于一个面积为 890 平方英尺的房屋，就可以根据上面这个集合中对应的值来把特征向量的这一项的值设置为3.然后就可以用朴素贝叶斯算法，并且将 $p(x_i|y)$ 作为多项式分布来进行建模。当原生的连续值的属性不太容易用一个多元正态分布来进行建模的时候，将其特征向量离散化然后使用朴素贝叶斯法来替代高斯判别分析法，通常能形成一个更好的分类器。</p>
<h2 id="Python实现"><a href="#Python实现" class="headerlink" title="Python实现"></a>Python实现</h2><p>下面的代码首先生成了两个服从高斯分布的点，并按照最大似然估计计算出了相关参数，画出了分界线。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div></pre></td><td class="code"><pre><div class="line"># -*- coding:utf-8 -*-</div><div class="line"></div><div class="line">import matplotlib.pyplot as plt</div><div class="line">import numpy as np</div><div class="line"></div><div class="line"># 随机生成两组服从高斯分布的数据</div><div class="line">mean0 = [2, 3]</div><div class="line">cov = np.mat([[1, 0], [0, 2]])</div><div class="line">x0 = np.random.multivariate_normal(mean0, cov, 200).T</div><div class="line">y0 = np.zeros(np.shape(x0)[1])</div><div class="line"></div><div class="line">mean1 = [7, 8]</div><div class="line">cov = np.mat([[1, 0], [0, 2]])</div><div class="line">x1 = np.random.multivariate_normal(mean1, cov, 200).T</div><div class="line">y1 = np.ones(np.shape(x1)[1])</div><div class="line"></div><div class="line"># 把两组数据整合到一个空间内</div><div class="line">x = np.array([np.concatenate((x0[0], x1[0])), np.concatenate((x0[1], x1[1]))])</div><div class="line">y = np.array([np.concatenate((y0, y1))])</div><div class="line">m = np.shape(x)[1]</div><div class="line"></div><div class="line">xplot0 = x0</div><div class="line">xplot1 = x1</div><div class="line"></div><div class="line"># 计算最大似然估计时参数的值</div><div class="line">phi = (1.0/m)*len(y1)</div><div class="line">u0 = np.mean(x0, axis=1)</div><div class="line">u1 = np.mean(x1, axis=1)</div><div class="line"></div><div class="line"># 计算sigma</div><div class="line">x0 = x0.T</div><div class="line">x1 = x1.T</div><div class="line">x = x.T</div><div class="line"></div><div class="line">x0_sub_u0 = x0-u0</div><div class="line">x1_sub_u1 = x1-u1</div><div class="line">x_sub_u = np.concatenate([x0_sub_u0, x1_sub_u1])</div><div class="line">x_sub_u = np.mat(x_sub_u)</div><div class="line"></div><div class="line">sigma = (1.0/m)*(x_sub_u.T*x_sub_u)</div><div class="line"></div><div class="line"># 把u0-u1的垂直平分线作为分界线</div><div class="line">midPoint = [(u0[0]+u1[0])/2.0, (u0[1]+u1[1])/2.0]</div><div class="line">k = (u1[1]-u0[1])/(u1[0]-u0[0])</div><div class="line">x = range(-2, 11)</div><div class="line">y = [(-1.0/k)*(i-midPoint[0])+midPoint[1] for i in x]</div><div class="line"></div><div class="line"></div><div class="line"># 描绘两个分布的等高线</div><div class="line">def gaussian_2d(xx, yy, xx0, yy0):</div><div class="line">    return np.exp(-0.5*((xx-xx0)**2+0.5*(yy-yy0)**2))</div><div class="line"></div><div class="line">delta = 0.025</div><div class="line">xgrid0 = np.arange(-2, 6, delta)</div><div class="line">ygrid0 = np.arange(-2, 6, delta)</div><div class="line">xgrid1 = np.arange(3, 11, delta)</div><div class="line">ygrid1 = np.arange(3, 11, delta)</div><div class="line">X0, Y0 = np.meshgrid(xgrid0, ygrid0)</div><div class="line">X1, Y1 = np.meshgrid(xgrid1, ygrid1)</div><div class="line">Z0 = gaussian_2d(X0, Y0, 2, 3)</div><div class="line">Z1 = gaussian_2d(X1, Y1, 7, 8)</div><div class="line"></div><div class="line"># 作图</div><div class="line">plt.figure()</div><div class="line">plt.clf()</div><div class="line">plt.plot(xplot0[0], xplot0[1], &apos;ro&apos;)</div><div class="line">plt.plot(xplot1[0], xplot1[1], &apos;bo&apos;)</div><div class="line">plt.plot(u0[0], u0[1], &apos;y*&apos;, markersize=10)</div><div class="line">plt.plot(u1[0], u1[1], &apos;y*&apos;, markersize=10)</div><div class="line">plt.plot(x, y)</div><div class="line">CS0 = plt.contour(X0, Y0, Z0)</div><div class="line">plt.clabel(CS0)</div><div class="line">CS1 = plt.contour(X1, Y1, Z1)</div><div class="line">plt.clabel(CS1)</div><div class="line">plt.title(&quot;Gaussian Discriminant Analysis&quot;)</div><div class="line">plt.xlabel(&apos;Feature Dimension (0)&apos;)</div><div class="line">plt.ylabel(&apos;Feature Dimension (1)&apos;)</div><div class="line">plt.show()</div></pre></td></tr></table></figure>
<p>运行结果：<br><img src="http://otceoztx6.bkt.clouddn.com/css229-note-0501.png" alt=""></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/公开课笔记/" rel="tag"># 公开课笔记</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/07/30/cs229-4/" rel="next" title="第四集 牛顿方法">
                <i class="fa fa-chevron-left"></i> 第四集 牛顿方法
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/08/02/cs229-6/" rel="prev" title="第六集 朴素贝叶斯算法">
                第六集 朴素贝叶斯算法 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="ZHANG ZH.Y." />
          <p class="site-author-name" itemprop="name">ZHANG ZH.Y.</p>
           
              <p class="site-description motion-element" itemprop="description">一个<br>为了不做程序员而努力搬砖的<br>代码狗</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">35</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#理论知识"><span class="nav-number">1.</span> <span class="nav-text">理论知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#高斯判别分析（Gaussian-Discriminant-Analysis）"><span class="nav-number">1.1.</span> <span class="nav-text">高斯判别分析（Gaussian Discriminant Analysis）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#多元正态分布（Multivariate-Normal-Distribution）"><span class="nav-number">1.1.1.</span> <span class="nav-text">多元正态分布（Multivariate Normal Distribution）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高斯判别分析模型（Gaussian-Discriminant-Analysis-Model）"><span class="nav-number">1.1.2.</span> <span class="nav-text">高斯判别分析模型（Gaussian Discriminant Analysis Model）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#高斯判别分析与逻辑回归（GDA-and-Logistic-Regression）"><span class="nav-number">1.1.3.</span> <span class="nav-text">高斯判别分析与逻辑回归（GDA and Logistic Regression）</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#朴素贝叶斯算法（Naive-Bayes）"><span class="nav-number">1.2.</span> <span class="nav-text">朴素贝叶斯算法（Naive Bayes）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Python实现"><span class="nav-number">2.</span> <span class="nav-text">Python实现</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZHANG ZH.Y.</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
