<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="公开课笔记," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="理论知识假如我们有一个数据集，里面的数据是俄勒冈州波特兰市的 47 套房屋的面积和价格， 上述数据映射到坐标系中如下图所示，我们应该怎么样才能从中找到房价和面积的关系呢，">
<meta name="keywords" content="公开课笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="第二集 监督学习的应用：梯度下降">
<meta property="og:url" content="http://zzysay.github.io/2017/07/26/cs229-2/index.html">
<meta property="og:site_name" content="ZZY SAY">
<meta property="og:description" content="理论知识假如我们有一个数据集，里面的数据是俄勒冈州波特兰市的 47 套房屋的面积和价格， 上述数据映射到坐标系中如下图所示，我们应该怎么样才能从中找到房价和面积的关系呢，">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img001.jpg">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img002.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img003.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img004.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img005.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img006.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img007.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img008.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img009.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img010.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img011.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img012.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img013.jpg?imageMogr2/thumbnail/!50p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img014.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img015.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img016.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img017.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img018.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img019.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img020.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img021.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img022.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img023.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img024.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img025.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img026.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img027.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img028.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img029.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img030.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img031.jpg?imageMogr2/thumbnail/!75p">
<meta property="og:image" content="http://otceoztx6.bkt.clouddn.com/css229-note-0201.png">
<meta property="og:updated_time" content="2017-08-02T09:25:19.312Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="第二集 监督学习的应用：梯度下降">
<meta name="twitter:description" content="理论知识假如我们有一个数据集，里面的数据是俄勒冈州波特兰市的 47 套房屋的面积和价格， 上述数据映射到坐标系中如下图所示，我们应该怎么样才能从中找到房价和面积的关系呢，">
<meta name="twitter:image" content="http://otceoztx6.bkt.clouddn.com/cs229-note-img001.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zzysay.github.io/2017/07/26/cs229-2/"/>





  <title>第二集 监督学习的应用：梯度下降 | ZZY SAY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZZY SAY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">I AM WHO I AM.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://zzysay.github.io/2017/07/26/cs229-2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZHANG ZH.Y.">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZZY SAY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">第二集 监督学习的应用：梯度下降</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-07-26T15:41:19+08:00">
                2017-07-26
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/Andrew-Ng公开课/" itemprop="url" rel="index">
                    <span itemprop="name">Andrew Ng公开课</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="理论知识"><a href="#理论知识" class="headerlink" title="理论知识"></a>理论知识</h2><p>假如我们有一个数据集，里面的数据是俄勒冈州波特兰市的 47 套房屋的面积和价格，<br><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img001.jpg" alt=""></p>
<p>上述数据映射到坐标系中如下图所示，我们应该怎么样才能从中找到房价和面积的关系呢，</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img002.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<a id="more"></a>
<p>用更加规范的方式来描述监督学习问题：我们的目标是，给定一个训练集，来让机器学习一个函数 h: X → Y，让 h(x) 能是一个与对应的真实 y 值比较接近的评估值。这个函数 h  就被叫做<strong>假设</strong>（hypothesis）。这个过程可以用如下的图来表示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img003.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>如果我们要预测的<strong>目标变量</strong>是<strong>连续</strong>的，比如在我们这个房屋价格-面积的案例中，这种学习问题就被称为<strong>回归问题</strong>。如果 y 只能取一小部分的离散的值（比如给定房屋面积，我们要来确定这个房子是一个住宅还是公寓），这样的问题就叫做<strong>分类问题</strong>。</p>
<h3 id="线性回归（Linear-Regression）"><a href="#线性回归（Linear-Regression）" class="headerlink" title="线性回归（Linear Regression）"></a>线性回归（Linear Regression）</h3><p>为了让我们的房屋案例更有意思，咱们稍微对数据集进行一下补充，增加上每一个房屋的卧室数目，</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img004.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>现在，<strong>输入特征</strong> x 就是在 R2 范围取值的一个二维向量了。例如 x1(i) 就是训练集中第 i 个房屋的面积，而 x1(i) 就是训练集中第 i 个房屋的卧室数目。要进行这个监督学习，我们必须得确定好如何在计算机里面对这个<strong>函数</strong>/<strong>假设</strong> h 进行表示。咱们现在刚刚开始，就来个简单点的，咱们把 y 假设为一个以 x 为变量的线性函数：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img005.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>这里的 θi 是<strong>参数</strong>（也可以叫做<strong>权重</strong>），是从 X 到 Y的线性函数映射的空间参数。在不至于引起混淆的情况下，我们可以简写成 h(x)。另外为了简化公式，我们还设 x0 = 1。这样简化之后就有了：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img006.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>等式的最右边的 θ 和 x 都是向量，等式中的 n 是输入变量的个数（不包括x0）。</p>
<p>现在，给定了一个<strong>训练集</strong>了，我们怎么来挑选/学习参数θ呢？一个看上去比较合理的方法就是让  h(x) 尽量逼近 y，至少对已有的训练样本能适用。用公式的方式来表示的话，就要定义一个函数，来衡量对于每个不同的 θ 值，h(x(i)) 与对应的 y(i) 的距离。这样用如下的方式定义了一个  <em>成本函数</em>  （<strong>cost function</strong>）:</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img007.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<h3 id="最小均方算法（LMS-Algorithm）"><a href="#最小均方算法（LMS-Algorithm）" class="headerlink" title="最小均方算法（LMS Algorithm）"></a>最小均方算法（LMS Algorithm）</h3><p>我们希望选择一个能让 J(θ) 最小的 θ 值。我们先用一个搜索的算法，从某一个对 θ 的“初始猜测值”，然后对 θ 值不断进行调整，来让 J(θ) 逐渐变小，最好是直到我们能够达到一个使 J(θ) 最小的  θ。具体来说，我们可以使用<strong>梯度下降法</strong>（gradient descent algorithm），这个方法就是从某一个 θ 的初始值开始，然后逐渐重复更新：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img008.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>这里的 α 也称为学习速率。这个算法是很自然的，逐步重复朝向 J 降低最快的方向移动。</p>
<p>要实现这个算法，我们需要解决等号右边的导数项。首先来解决只有一组训练样本 (x, y) 的情况，这样就可以忽略掉等号右边对 J 的求和项目了。公式就简化下面这样：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img009.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>对单个训练样本，更新规则如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img010.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>当只有一个训练样本的时候，我们推导出了以上的LMS规则。而扩展到多组数据样本中时，就得到了以下的算法，</p>
<p>重复直到收敛</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img011.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>读者很容易能证明，这个更新规则实际上就是对原始的成本函数 J 进行简单的梯度下降。这一方法在每一个步长内检查所有整个训练集中的所有样本，也叫做批量梯度下降法（batch gradient descent）。这里要注意，因为梯度下降法容易被局部最小值影响，而我们要解决的这个线性回归的优化问题只能有一个全局的而不是局部的最优解；因此，梯度下降法应该总是收敛到全局最小值（假设学习速率 α 不设置的过大）。J 是一个凸的二次函数。下面是一个样例，其中对一个二次函数使用了梯度下降法来找到最小值。</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img012.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>上图的椭圆就是一个二次函数的轮廓图。图中还有梯度下降法生成的规矩，初始点位置在(48,30)。图中的画的 x （用直线连接起来了）标记了梯度下降法所经过的 θ 的可用值。</p>
<p>对之前的房屋数据集进行批量梯度下降来拟合 θ，把房屋价格当作房屋面积的函数来进行预测，我们得到的结果是 θ0 = 71.27, θ1 = 0.1345。如果把 hθ(x) 作为一个定义域在 x 上的函数来投影，同时也投上训练集中的已有数据点，会得到下面这幅图：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img013.jpg?imageMogr2/thumbnail/!50p" alt=""></p>
<p>如果在数据集中添加上卧室数目作为输入特征，那么得到的结果就是 θ0 = 89.60, θ1 = 0.1392, θ2 = -8.738。</p>
<p>这个结果就是用批量梯度下降法来获得的。此外还有另外一种方法能够替代批量梯度下降法，这种方法效果也不错。如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img014.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>在这个算法里，我们对整个训练集进行了循环遍历，每次遇到一个训练样本，根据每个单一训练样本的误差梯度来对参数进行更新。这个算法叫做<strong>随机梯度下降法（stochastic gradient descent）</strong>，或者叫<strong>增量梯度下降法（incremental gradient descent）</strong>。批量梯度下降法要在运行第一步之前先对整个训练集进行扫描遍历，当训练集的规模 m 变得很大的时候，因此引起的性能开销就很不划算了；随机梯度下降法就没有这个问题，而是可以立即开始，对查询到的每个样本都进行运算。通常情况下，随机梯度下降法查找到足够接近最低值的 θ 的速度要比批量梯度下降法更快一些。(也要注意，也有可能会一直无法<strong>收敛（converge）</strong>到最小值，这时候 θ 会一直在 J(θ) 最小值附近震荡；不过通常情况下足以满足我们的精度要求。</p>
<p>所以在训练大规模数据集的时候，我们通常更推荐使用的都是随机梯度下降法，而不是批量梯度下降法。</p>
<h3 id="法方程（The-Normal-Equations）"><a href="#法方程（The-Normal-Equations）" class="headerlink" title="法方程（The Normal Equations）"></a>法方程（The Normal Equations）</h3><p>上文中的梯度下降法是一种找出 J 最小值的办法。还有一种方法就是，我们直接利用找对应导数为 0 位置的 θj，这样就能找到 J 的最小值了</p>
<h4 id="矩阵导数（Matrix-Derivatives）"><a href="#矩阵导数（Matrix-Derivatives）" class="headerlink" title="矩阵导数（Matrix Derivatives）"></a>矩阵导数（Matrix Derivatives）</h4><p>假如有一个函数 f: Rm×n → R 从 m * n大小的矩阵映射到实数域，那么就可以定义当矩阵为 A 的时候有导函数 f 如下所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img015.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>因此，这个梯度 <img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img016.jpg?imageMogr2/thumbnail/!75p" alt=""> 本身也是一个 m<em>n 的矩阵，其中的第 (i, j)个元素是 ∂f / ∂Aij 。假如<img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img017.jpg?imageMogr2/thumbnail/!75p" alt="">是一个 2</em>2 矩阵，然后给定的函数 f：R2×2 → R 为：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img018.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>这里面的 Aij 表示的意思是矩阵 A 的第(i, j) 个元素。然后就有了梯度：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img019.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>然后引入 <strong>trace</strong> 求迹运算，简写为 <strong>tr</strong>。对于一个给定的 n*n 方形矩阵 A，它的迹定义为对角项和：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img020.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>假如 a 是一个实数，实际上 a 就可以看做是一个 1*1 的矩阵，那么就有 a 的迹 tr a = a。</p>
<p>如果有两个矩阵 A 和 B，能够满足 AB 为方阵，trace 求迹运算就有一个特殊的性质： trAB = trBA. 在此基础上进行推论，就能得到类似下面这样的等式关系：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img021.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>下面这些和求迹运算相关的等量关系也很容易证明。其中 A 和 B 都是方形矩阵，a 是一个实数：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img022.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img023.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<h4 id="最小二乘法回顾（Least-Squares-Revisited）"><a href="#最小二乘法回顾（Least-Squares-Revisited）" class="headerlink" title="最小二乘法回顾（Least Squares Revisited）"></a>最小二乘法回顾（Least Squares Revisited）</h4><p>给定一个训练集，把设计矩阵（design matrix） X 设置为一个 m*n 矩阵，这个矩阵里面包含了训练样本的输入值作为每一行：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img024.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>设 $ \vec y $ 是一个 m 维向量（m-dimensional vector），其中包含了训练集中的所有目标值：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img025.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>因为$ h_{θ}(x^{(i)}) = (x^{(i)})^Tθ $，所以可以证明存在下面这种等量关系：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img026.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>对于向量 z ，则有 $ z^T z = z^2 $，因此利用这个性质，可以推出：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img027.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>最后，要让 J 的值最小，就要找到导数为 0 的点。结合等式（2）和等式（3），就能得到下面这个等式（5）：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img028.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>因此就有，</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img029.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>要让 J 取得最小值，就使导数为 0 ，然后就得到了下面的<strong>法线方程（normal equations）</strong>，</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img030.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<p>所以让 J(θ) 取值最小的 θ 就是，<br><img src="http://otceoztx6.bkt.clouddn.com/cs229-note-img031.jpg?imageMogr2/thumbnail/!75p" alt=""></p>
<h2 id="Python实现"><a href="#Python实现" class="headerlink" title="Python实现"></a>Python实现</h2><p>有这样一组数据，在磁盘中被存储为.csv格式，内容如下表所示：</p>
<p><img src="http://otceoztx6.bkt.clouddn.com/css229-note-0201.png" alt=""></p>
<p>其中，待训练数据A、B为自变量，C为因变量。1-10为训练集，11-15为测试集。</p>
<p>经过调试，当学习率为0.05，迭代次数为5000次时，可以达到最佳的学习效果。<br>通常情况下，循环次数越多，越接近真实值。一般达到以下的任意一种情况即可以停止学习循环：</p>
<ol>
<li>权重的更新低于某个阈值；</li>
<li>预测的错误率低于某个阈值；</li>
<li>达到预设的最大循环次数；</li>
</ol>
<p>具体Python实现过程及相关说明如下所示：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> genfromtxt</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 把A,B存入trainData，C存入trainLabel</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getData</span><span class="params">(dataSet)</span>:</span></div><div class="line">    m, n = np.shape(dataSet)</div><div class="line">    trainData = np.ones((m, n))</div><div class="line">    trainData[:, :<span class="number">-1</span>] = dataSet[:, :<span class="number">-1</span>]</div><div class="line">    trainLabel = dataSet[:, <span class="number">-1</span>]</div><div class="line">    <span class="keyword">return</span> trainData, trainLabel</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">batchGradientDescent</span><span class="params">(x, y, theta, alpha, m, maxIterations)</span>:</span></div><div class="line">    xTrains = x.transpose()</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, maxIterations):</div><div class="line">        hypothesis = np.dot(x, theta)  <span class="comment"># 按照当前theta计算出的y</span></div><div class="line">        loss = y - hypothesis  <span class="comment"># 当前误差</span></div><div class="line">        gradient = np.dot(xTrains, loss) / m  <span class="comment"># 梯度</span></div><div class="line">        theta = theta + alpha * gradient  <span class="comment"># 更新theta</span></div><div class="line">    <span class="keyword">return</span> theta</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(x, theta)</span>:</span></div><div class="line">    m, n = np.shape(x)</div><div class="line">    xTest = np.ones((m, n+<span class="number">1</span>))</div><div class="line">    xTest[:, :<span class="number">-1</span>] = x</div><div class="line">    yP = np.dot(xTest, theta)</div><div class="line">    <span class="keyword">return</span> yP</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># 读取训练集信息并存入dataSet中</span></div><div class="line">dataPath = <span class="string">'1_train.csv'</span></div><div class="line">dataSet = genfromtxt(dataPath, delimiter=<span class="string">','</span>)</div><div class="line"></div><div class="line"></div><div class="line">trainData, trainLabel = getData(dataSet)  <span class="comment"># 训练集数据</span></div><div class="line">m, n = np.shape(trainData)  <span class="comment"># 训练集大小，m为样本总数，n为样本特征数</span></div><div class="line">theta = np.ones(n)  <span class="comment"># 初始化theta全为1</span></div><div class="line">alpha = <span class="number">0.1</span>  <span class="comment"># 学习率为0.1</span></div><div class="line">maxIteration = <span class="number">5000</span>  <span class="comment"># 迭代次数为5000次</span></div><div class="line"></div><div class="line">theta = batchGradientDescent(trainData, trainLabel, theta, alpha, m, maxIteration)</div><div class="line"></div><div class="line">x = np.array([[<span class="number">3.1</span>, <span class="number">5.5</span>], [<span class="number">3.3</span>, <span class="number">5.9</span>], [<span class="number">3.5</span>, <span class="number">6.3</span>], [<span class="number">3.7</span>, <span class="number">6.7</span>], [<span class="number">3.9</span>, <span class="number">7.1</span>]])</div><div class="line"></div><div class="line">print(theta)</div><div class="line">print(predict(x, theta))</div></pre></td></tr></table></figure></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/公开课笔记/" rel="tag"># 公开课笔记</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/07/25/cs229-1/" rel="next" title="第一集 机器学习的动机与应用">
                <i class="fa fa-chevron-left"></i> 第一集 机器学习的动机与应用
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/07/28/cs229-3/" rel="prev" title="第三集 欠拟合与过拟合的概念">
                第三集 欠拟合与过拟合的概念 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="ZHANG ZH.Y." />
          <p class="site-author-name" itemprop="name">ZHANG ZH.Y.</p>
           
              <p class="site-description motion-element" itemprop="description">一个<br>为了不做程序员而努力搬砖的<br>代码狗</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">14</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">4</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#理论知识"><span class="nav-number">1.</span> <span class="nav-text">理论知识</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#线性回归（Linear-Regression）"><span class="nav-number">1.1.</span> <span class="nav-text">线性回归（Linear Regression）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最小均方算法（LMS-Algorithm）"><span class="nav-number">1.2.</span> <span class="nav-text">最小均方算法（LMS Algorithm）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#法方程（The-Normal-Equations）"><span class="nav-number">1.3.</span> <span class="nav-text">法方程（The Normal Equations）</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#矩阵导数（Matrix-Derivatives）"><span class="nav-number">1.3.1.</span> <span class="nav-text">矩阵导数（Matrix Derivatives）</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#最小二乘法回顾（Least-Squares-Revisited）"><span class="nav-number">1.3.2.</span> <span class="nav-text">最小二乘法回顾（Least Squares Revisited）</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Python实现"><span class="nav-number">2.</span> <span class="nav-text">Python实现</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZHANG ZH.Y.</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
