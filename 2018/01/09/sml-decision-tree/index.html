<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="机器学习,决策树," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="决策树模型概述">
<meta name="keywords" content="机器学习,决策树">
<meta property="og:type" content="article">
<meta property="og:title" content="决策树模型">
<meta property="og:url" content="http://zzysay.github.io/2018/01/09/sml-decision-tree/index.html">
<meta property="og:site_name" content="ZZY SAY">
<meta property="og:description" content="决策树模型概述">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154627772145.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154627215377.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154633643209.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154633863963.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154641610099.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154673720821.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154680562782.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154683588148.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154750569074.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154750925045.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154751124045.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154752163451.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154752313013.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154752600065.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154820966945.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154807412850.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154836884865.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154837084672.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154899883921.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154877338124.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154877849795.jpg">
<meta property="og:image" content="http://p1auo1a1h.bkt.clouddn.com/15154878291741.jpg">
<meta property="og:updated_time" content="2018-02-07T13:41:52.794Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="决策树模型">
<meta name="twitter:description" content="决策树模型概述">
<meta name="twitter:image" content="http://p1auo1a1h.bkt.clouddn.com/15154627772145.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zzysay.github.io/2018/01/09/sml-decision-tree/"/>





  <title>决策树模型 | ZZY SAY</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZZY SAY</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">All in the Game</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://zzysay.github.io/2018/01/09/sml-decision-tree/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhenyu Zhang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZZY SAY">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">决策树模型</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-01-09T17:30:42+08:00">
                2018-01-09
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Class-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Class Notes</span>
                  </a>
                </span>

                
                
                  , 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Class-Notes/Statistical-Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Statistical Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="决策树模型概述"><a href="#决策树模型概述" class="headerlink" title="决策树模型概述"></a>决策树模型概述</h2><p><img src="http://p1auo1a1h.bkt.clouddn.com/15154627772145.jpg" alt=""></p>
<a id="more"></a>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154627215377.jpg" alt=""></p>
<p>决策树方法的目标就是在一个树的结构上，根据节点的判断来搜索类别，对于一个二分判决问题，我们可以将其类比为二叉树，用内部节点代表一个特征或者属性，用叶子节点代表一个类别。</p>
<p>决策树模型呈树形结构，有着树结构的优点：不必测试所有特征和区域，但是也面临着两个问题：一是高维特征空间不可见，<strong>如何确定节点？</strong>，二是我们怎么知道应该<strong>从那些特征开始？</strong> 这也就引出了决策树模型的关键问题：</p>
<ul>
<li>问题数</li>
<li>划分（问题）选择</li>
<li>决策树生成</li>
<li>决策树剪枝</li>
</ul>
<h3 id="问题数"><a href="#问题数" class="headerlink" title="问题数"></a>问题数</h3><p><strong>离散值情况：</strong>以特征或者特征可能的离散值作为问题<br><img src="http://p1auo1a1h.bkt.clouddn.com/15154633643209.jpg" alt=""></p>
<p><strong>连续值情况：</strong>以每个维度的样本特征作为问题<br><img src="http://p1auo1a1h.bkt.clouddn.com/15154633863963.jpg" alt=""></p>
<p>无论特征值是连续还是离散，确定每个属性所产生的候选问题后，最后的候选问题总数是：<br>$$N = \sum N_i$$</p>
<h3 id="划分选择"><a href="#划分选择" class="headerlink" title="划分选择"></a>划分选择</h3><p>我们定义非纯度 $IM(Impurity\;Measure)$ 作为衡量度量类别划分优劣的标准，$IM$ 定义应该满足以下两点：</p>
<ul>
<li>$IM$ 最大时，当前的划分应使所有数据占各类别的比例相等：<br>$$ p = \frac {1} {number\;of\;classes}$$</li>
<li>$IM$ 最小时为 $0$，当前的划分使所有数据都是相同类，这也是我们的<strong>期望目标</strong>。</li>
</ul>
<p>所以最后的划分目标是：选择能最大程度上减少类别非纯度的问题作为划分节点。非纯度的减少量为:<br>$$ \Delta I(t) = 1 - \frac {N_{tY}} {N_t}I(tY) - \frac {N_{tN}} {N_t}I(tN) $$</p>
<p>$IM$ 在不同的算法中有着不同的度量方式，较为典型的就是<strong>熵度量</strong>和<strong>基尼度量</strong></p>
<h4 id="非纯度的熵度量"><a href="#非纯度的熵度量" class="headerlink" title="非纯度的熵度量"></a>非纯度的熵度量</h4><p>$$ I(D) = Entropy\,(D) = - \sum_{i=1}^kp_i\log p_i $$<br><img src="http://p1auo1a1h.bkt.clouddn.com/15154641610099.jpg" alt=""></p>
<p><strong>信息增益</strong></p>
<p>$$ Gain\,(D,a) = Entropy\,(D) - \sum_{v=1}^V \frac {|D^v|} {|D|}  Entropy\,(D^v) $$</p>
<p>其中 $v$ 是特征 $a$ 的问题数</p>
<p>显然，$ Gain\,(D,a) $ 偏好划分问题数 $v$ 多的特征。直观上的理解是：划分区间越细，区域内的纯度也就越高，相对未划分时的信息增益也就越大，一个极端的情况是每个区间只有一个样本，此时信息熵为 $0$，划分的信息增益即为$ Gain\,(D,a) $。</p>
<p>$ID3$ 决策树使用了信息增益作为非纯度的度量标准，信息增益越大，划分效果越好。</p>
<p><strong>信息增益比</strong></p>
<p>$$ Gain_ratio\,(D,a) = \frac {Gain\,(D,a)} {IV(a)}<br>\\s.t.\; IV(a) = - \sum_{v=1}^V \frac {|D^v|} {|D|} \log \frac {|D^v|} {|D|} $$</p>
<p>其中 $v$ 是特征 $a$ 的问题数，$IV(a)$ 实际上就是数据集 $D$ 关于特征 $a$ 的信息熵</p>
<p>和信息增益不同，信息增益比可能对划分问题数 $v$ 少的特征有所偏好，因为 $v$ 越小 $IV(a)$ 也就越小，例如 $-\sum_{v=1}^3 \frac 1 3 \log \frac 1 3 \gt -\sum_{v=1}^2 \frac 1 2 \log \frac 1 2 $。</p>
<p>$C4.5$ 决策树使用了信息增益比作为非纯度的度量标准，信息增益比越大，划分效果越好。</p>
<h4 id="非纯度的基尼度量"><a href="#非纯度的基尼度量" class="headerlink" title="非纯度的基尼度量"></a>非纯度的基尼度量</h4><p>$$ I(D) = Gini\,(D) = \sum_{k=1}^Kp_k(1-p_k) = 1- \sum_{k=1}^K p_k^2$$</p>
<p><strong>基尼指数</strong></p>
<p>$$ Gini_index\,(D,a) = \sum_{v=1}^V \frac {|D^v|} {|D|} Gini\,(D^v) $$</p>
<p>$CART$ 决策树使用了基尼指数作为非纯度的度量标准，基尼指数越小，划分效果越好。</p>
<p><strong>停止划分</strong><br>叶子节点纯度达到预设阈值后，停止划分，并对叶子节点进行类别设置。 按概率最大的类别设定：<br>$$ j = \arg\max_i p_i $$</p>
<h3 id="决策树生成"><a href="#决策树生成" class="headerlink" title="决策树生成"></a>决策树生成</h3><p>决策树的生成过程和传统树结构的生成过程相同，都是一个<strong>自顶向下</strong>，不断增加节点的迭代过程。</p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154673720821.jpg" alt=""></p>
<h2 id="ID3-算法"><a href="#ID3-算法" class="headerlink" title="ID3 算法"></a>ID3 算法</h2><p>$ID3$ 算法的划分选择依据是最大化信息增益，以属性特征作为结点问题，划分选择的过程其实就是特征选择的过程。</p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154680562782.jpg" alt=""></p>
<p>$ID3$ 算法以信息增益作为非纯度的度量标准，所以在特征选择时，会倾向于选择特征取值较多的特征，也正是因为这个原因，$ID3$ 算法不能够处理连续的特征值，如果直接按照连续值的取值进行分类，分出的类别将会非常多，最后学得的决策树可能只有这一连续值特征，明显不具备泛化性能，若是简单地把连续值分成 $n$ 类，$n$ 的选择对特征选择有很大的影响，通常情况下人工很难找到优秀的一个 $n$。</p>
<h2 id="C4-5-算法"><a href="#C4-5-算法" class="headerlink" title="C4.5 算法"></a>C4.5 算法</h2><p>$C4.5$ 算法和 $ID3$ 算法类似，把非纯度的度量标准由信息增益改成了信息增益比，于是有了以下改进：</p>
<ul>
<li>克服了用信息增益选择特征时偏向选择取值多的特征</li>
<li>能够对连续值进行离散化</li>
<li>能够处理缺失值</li>
</ul>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154683588148.jpg" alt=""></p>
<h3 id="连续值处理"><a href="#连续值处理" class="headerlink" title="连续值处理"></a>连续值处理</h3><ol>
<li>对特征的取值进行升序排序</li>
<li>两个特征取值的<strong>平均值</strong>作为候选划分点，将数据集分成两部分，计算每个候选划分点的<strong>信息增益</strong></li>
<li>选择修正后信息增益最大的划分点作为该特征的最佳分裂点</li>
<li>计算最佳划分点的<strong>信息增益率</strong>作为特征的信息增益率</li>
</ol>
<p>此处需对最佳划分点的信息增益进行修正：减去 $\log_2 \frac {N-1} {|D|}$，其中 $N$ 是连续特征的取值个数，$D$ 是训练数据数目，此修正使当离散属性和连续属性并存时，$C4.5$ 算法倾向于选择连续特征做最佳树分裂点。</p>
<p><strong>算法实例</strong></p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154750569074.jpg" alt=""><br><img src="http://p1auo1a1h.bkt.clouddn.com/15154750925045.jpg" alt=""><br><img src="http://p1auo1a1h.bkt.clouddn.com/15154751124045.jpg" alt=""></p>
<h3 id="缺失值处理"><a href="#缺失值处理" class="headerlink" title="缺失值处理"></a>缺失值处理</h3><p>对于缺失值，我们需要解决两个问题：</p>
<ol>
<li>（训练）如何在属性值缺失的情况下进行划分属性选择？</li>
<li>（测试）给定划分属性，若样本在该属性上的值缺失，如何对样本进行分类？</li>
</ol>
<p>对于属性 $a$，我们用 $\rho$ 来表示在该属性上无缺失值样本所占的比例，$\tilde{p_k}$ 表示在该属性上无缺失值样本中第 $k$ 类所占的比例，$\tilde{r_v}$ 表示无缺失值样本中在属性 $a$ 上取值 $a^v$ 的样本的比例。 </p>
<p>对于问题 $1$：<br>基于以上定义，我们可以把信息增益的公式推广为：</p>
<p>$$ Gain\,(D,a) = \rho \times Gain\,(\tilde{D},a) = \rho \times \left( Entropy\,(\tilde{D}) - \sum_{v=1}^V \tilde{r_v} Entropy\,(\tilde{D}^v) \right) $$<br>其中<br>$$ Entropy\,(\tilde{D}) = - \sum_{k=1}^K \tilde{p_k} \log_2\tilde{p_k} $$</p>
<p>对于问题 $2$：</p>
<p>若样本 $x$ 在属性 $a$ 上的取值已知，则将 $x$ 划分到与其取值对应的子节点，样本权重 $w_x$ 不变；若样本 $x$ 在属性 $a$ 上的取值未知，则将 $x$ 划分到所有子节点，且样本权值在属性 $a^v$ 对应的子节点中调整为 $\tilde{r_v} $。直观地看，就是让同一个样本以不同的概率划分到不同的子节点中去。</p>
<p><strong>算法实例</strong></p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154752163451.jpg" alt=""><br><img src="http://p1auo1a1h.bkt.clouddn.com/15154752313013.jpg" alt=""><br><img src="http://p1auo1a1h.bkt.clouddn.com/15154752600065.jpg" alt=""></p>
<h2 id="CART-算法"><a href="#CART-算法" class="headerlink" title="CART 算法"></a>CART 算法</h2><p>$Classification\;And\;Regression\;Tree,\;CART$ 是分类与回归树，与 $ID3$ 和 $C4.5$ 不同，$CART$ 不单单能够用户分类，同样也可以用于回归，其本质是一个<strong>二叉树</strong>，左分支是“是”，右分支是“否”。生成过程的第一步是生成尽可能大的决策树，第二步使用验证集对决策树进行剪枝。</p>
<h3 id="回归树"><a href="#回归树" class="headerlink" title="回归树"></a>回归树</h3><p>回归树在构建过程中始终遵循平方误差最小化的准则</p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154820966945.jpg" alt=""></p>
<p>其中，$c_m$ 为元素在空间 $R_m$ 上的输出，显然当 $c_m$ 取 $R_m$ 中所有实例输出的均值时，平方误差最小。在式 $(5.21)$ 中，对每个不同的 $j$ 都有不同的 $c_1$ 和 $c_2$，此时 $c$ 可以看到当前区域的均值，而整个式子就是寻找一组使划分后两个区域的方差和最小的 $j,s$。</p>
<h3 id="分类树"><a href="#分类树" class="headerlink" title="分类树"></a>分类树</h3><p>分类树使用基尼指数选择最优特征，同时决定该特征的最优二值切分点，在特征 $a$ 的条件下，集合 $D$ 的基尼指数为：</p>
<p>$$ Gini\,(D,a) = \frac {|D_1|}{|D|} Gini\,(D_1) + \frac {|D_2|}{|D|} Gini\,(D_2)$$</p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154807412850.jpg" alt=""></p>
<h2 id="剪枝算法"><a href="#剪枝算法" class="headerlink" title="剪枝算法"></a>剪枝算法</h2><h3 id="ID3及C4-5算法的剪枝"><a href="#ID3及C4-5算法的剪枝" class="headerlink" title="ID3及C4.5算法的剪枝"></a>ID3及C4.5算法的剪枝</h3><p>构造整体损失函数：<br>$$ C_{\alpha}\left( T \right) = C\left( T \right) + \alpha\left| T \right|$$</p>
<p>其中 $C(T)$ 表示模型对训练数据的预测误差，$|T|$ 表示模型复杂度，通常可以用节点数量来表示，$\alpha \ge 0 $ 控制两者之间的影响，较大的 $\alpha$ 会促使选择较为简单的模型，反之则会选择较为复杂的模型，剪枝的过程也就是当 $\alpha$ 给定时，选择损失函数最小的模型。</p>
<p><strong>算法描述</strong></p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154836884865.jpg" alt=""><br><img src="http://p1auo1a1h.bkt.clouddn.com/15154837084672.jpg" alt=""></p>
<p>由算法可以看出，式 $(5.15)$ 值考虑两个数的损失函数的差，其计算可以在<strong>局部进行</strong>。</p>
<h3 id="CART算法的剪枝"><a href="#CART算法的剪枝" class="headerlink" title="CART算法的剪枝"></a>CART算法的剪枝</h3><p>按照损失函数的定义，对于一个子树 $|T_t|$，有：</p>
<p>$$C_{\alpha}(T_t)=C(T_t)+\alpha |T_t|$$</p>
<p>对于单节点 $t$，有：</p>
<p>$$C_{\alpha}(T_t)=C(T_t)+\alpha $$</p>
<p>当 $\alpha=0$ 或者充分小时，在某一个 $\alpha$ 有：</p>
<p>$$C_{\alpha}(T_t)=C_{\alpha}(t)<br>\\ \alpha = \frac{C(t)-C_(T_t)}{|T_t|-1}$$</p>
<p>此时表示 $T_t$ 和 $t$ 有相同的损失函数值。</p>
<p>为此，对 $T_0$ 中每一个内部节点 $t$，计算</p>
<p>$$ g(t)=\frac{C(t)-C_(T_t)}{|T_t|-1} $$</p>
<p>它表示<strong>剪枝后</strong>整体损失函数减少的程度（抛开正则项），在 $T_0$ 中减去 $g(t)$ 最小的 $T_t$，得到子树 $T_1$，同时将最小的 $g(t)$ 设为 $\alpha_1$， $T_1$ 即为区间 $[\alpha_1, \alpha_2)$ 之间的最优子树，不断迭代，增加 $\alpha$ 的值，直至根节点。</p>
<p>对于同一棵树的结点， $\alpha$ 都是一样的，当 $\alpha$ 从 $0$ 开始缓慢增大，总会有某棵子树该剪，其他子树不该剪的情况，即 $\alpha$ 超过了某个结点的 $g(t)$，但还没有超过其他结点的 $g(t)$。这样随着 $\alpha$ 不断增大，不断地剪枝，就得到了 $n+1$ 棵嵌套的子树。</p>
<p><strong>算法描述</strong><br><img src="http://p1auo1a1h.bkt.clouddn.com/15154899883921.jpg" alt=""></p>
<p>对于子树 $T_k$ 来说，节点 $t$ 是当前 $\alpha$ 下最优的切分点，其它节点的 $g(t)$ 都比该节点的 $g(t)$ 大。</p>
<p>总的来说，就是 $ID3$ 和 $C4.5$ 剪枝时 $\alpha$ 是人为给定的，而 $CART$ 剪枝时的 $\alpha$ 是根据特征值在 $[0, +\infty)$ 找到一系列的值，从而得到一系列剪枝后的树，从中选取最优的。从最宏观的角度去考虑的话，就是利用 $\alpha$ 生成 $T_{\alpha}$。抽象一下，即从无限的实数中找寻有限个数的 $T_{\alpha}$。</p>
<h2 id="预剪枝与后剪枝"><a href="#预剪枝与后剪枝" class="headerlink" title="预剪枝与后剪枝"></a>预剪枝与后剪枝</h2><p><img src="http://p1auo1a1h.bkt.clouddn.com/15154877338124.jpg" alt=""></p>
<p>剪枝操作是防止决策树过拟合的有效方法，上图所示的是一个未经剪枝的决策树。</p>
<h3 id="预剪枝"><a href="#预剪枝" class="headerlink" title="预剪枝"></a>预剪枝</h3><p>预剪枝就是在树的构建过程（只使用训练集），设置一个阈值（样本个数小于预定阈值或基尼指数小于预定阈值），若当前节点划分前和划分后的误差超过这个阈值则进行划分，否则不进行划分，预剪枝基于“贪心”本质禁止这些分支展开，防止了过拟合的同时也带来了<strong>欠拟合</strong>的风险。</p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154877849795.jpg" alt=""></p>
<h3 id="后剪枝"><a href="#后剪枝" class="headerlink" title="后剪枝"></a>后剪枝</h3><p>后剪枝是先按照训练集生成一颗完整的决策树，随后按照验证集尝试不断回缩，设置一个阈值，若回缩后模型的精度和回缩前模型的精度差超过了这个阈值，则进行回缩（剪枝）。一般情况下，后剪枝决策树通常比预剪枝决策树保留了更多的分支，所以欠拟合的风险很小，<strong>泛化性能更好</strong>，但是后剪枝过程首先需要生成完整的决策树，并且自底向上地对所有非叶子节点逐一考察，因此<strong>时间开销远大于预剪枝和未剪枝决策树</strong>。</p>
<p><img src="http://p1auo1a1h.bkt.clouddn.com/15154878291741.jpg" alt=""></p>
<p>参考文献：<br>[1] 周晓飞,《统计机器学习》,中国科学院大学2017年秋季研究生课程<br>[2] 李航,《统计学习方法》,清华大学出版社<br>[3] 周志华,《机器学习》,清华大学出版社</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
            <a href="/tags/决策树/" rel="tag"># 决策树</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/07/sml-logistic-model/" rel="next" title="Logistic模型">
                <i class="fa fa-chevron-left"></i> Logistic模型
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/10/sml-boosting/" rel="prev" title="集成学习">
                集成学习 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Zhenyu Zhang" />
          <p class="site-author-name" itemprop="name">Zhenyu Zhang</p>
           
              <p class="site-description motion-element" itemprop="description">Survival with technology<br/>And living with art</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">39</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树模型概述"><span class="nav-number">1.</span> <span class="nav-text">决策树模型概述</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#问题数"><span class="nav-number">1.1.</span> <span class="nav-text">问题数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#划分选择"><span class="nav-number">1.2.</span> <span class="nav-text">划分选择</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#非纯度的熵度量"><span class="nav-number">1.2.1.</span> <span class="nav-text">非纯度的熵度量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#非纯度的基尼度量"><span class="nav-number">1.2.2.</span> <span class="nav-text">非纯度的基尼度量</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#决策树生成"><span class="nav-number">1.3.</span> <span class="nav-text">决策树生成</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ID3-算法"><span class="nav-number">2.</span> <span class="nav-text">ID3 算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#C4-5-算法"><span class="nav-number">3.</span> <span class="nav-text">C4.5 算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#连续值处理"><span class="nav-number">3.1.</span> <span class="nav-text">连续值处理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#缺失值处理"><span class="nav-number">3.2.</span> <span class="nav-text">缺失值处理</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CART-算法"><span class="nav-number">4.</span> <span class="nav-text">CART 算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#回归树"><span class="nav-number">4.1.</span> <span class="nav-text">回归树</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分类树"><span class="nav-number">4.2.</span> <span class="nav-text">分类树</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#剪枝算法"><span class="nav-number">5.</span> <span class="nav-text">剪枝算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ID3及C4-5算法的剪枝"><span class="nav-number">5.1.</span> <span class="nav-text">ID3及C4.5算法的剪枝</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CART算法的剪枝"><span class="nav-number">5.2.</span> <span class="nav-text">CART算法的剪枝</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#预剪枝与后剪枝"><span class="nav-number">6.</span> <span class="nav-text">预剪枝与后剪枝</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#预剪枝"><span class="nav-number">6.1.</span> <span class="nav-text">预剪枝</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#后剪枝"><span class="nav-number">6.2.</span> <span class="nav-text">后剪枝</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhenyu Zhang</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Pisces
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  


  

  

</body>
</html>
